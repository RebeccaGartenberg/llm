Microsoft: China plans to disrupt elections with AI-generated disinformation
April 5, 2024

						Ryan Daws is a senior editor at TechForge Media, with a seasoned background spanning over a decade in tech journalism. His expertise lies in identifying the latest technological trends, dissecting complex topics, and weaving compelling narratives around the most cutting-edge developments. His articles and interviews with leading industry figures have gained him recognition as a key influencer by organisations such as Onalytica. Publications under his stewardship have since gained recognition from leading analyst houses like Forrester for their performance. Find him on X (@gadget_ry) or Mastodon (@gadgetry@techhub.social)
			
Beijing is expected to ramp up sophisticated AI-generated disinformation campaigns to influence several high-profile elections in 2024, according to Microsoft’s threat intelligence team.
Microsoft warned that state-backed Chinese cyber groups – with assistance from North Korean actors – “are likely to target” the presidential and legislative elections in countries such as the US, South Korea, and India this year. Their primary tactic is projected to be the creation and dissemination on social media of AI-generated content skewed to “benefit their positions” in these races.
“While the impact of such content in swaying audiences remains low, China’s increasing experimentation in augmenting memes, videos, and audio will continue – and may prove effective down the line,” Microsoft cautioned in the report released Friday.
The company cited China’s recent “dry run” utilising AI-synthesised disinformation during Taiwan’s January presidential election as a harbinger of this emerging threat. Microsoft assessed that a pro-Beijing group known as Storm 1376 or Spamouflage Dragon made the first documented attempt by a state actor to influence a foreign vote using AI-manufactured content.
Tactics deployed by the Chinese-backed operatives included posting fake audio clips likely “generated by AI” that depicted a former presidential candidate endorsing a rival, as well as AI-generated memes leveling unfounded corruption allegations against the ultimately victorious pro-sovereignty candidate William Lai. The group also created AI-rendered “news anchors” to broadcast disinformation about Lai’s personal life.
“As populations in India, South Korea, and the United States head to the polls, we are likely to see Chinese cyber and influence actors, and to some extent North Korean cyber actors, work toward targeting these elections,” the Microsoft report stated.
The company added that Chinese groups are already attempting to map divisive issues and voting blocs in the US through orchestrated social media campaigns, potentially “to gather intelligence and precision on key voting demographics ahead of the US Presidential election.”
While flagging the risk, Microsoft acknowledged that AI-enabled disinformation has so far achieved limited success in shaping public opinion globally. But it warned that Beijing’s growing investment and increasing sophistication with the technology poses an escalating threat to the integrity of democratic elections worldwide.
(Photo by Element5 Digital)
See also: How to safeguard your business from AI-generated deepfakes
